#!/usr/bin/env python3
"""
LLMåŠ¨æ€éœ€æ±‚åˆ†æ - CLIå·¥å…·
ç”¨æˆ·è¯´ä»€ä¹ˆï¼ŒLLMå°±åˆ†æä»€ä¹ˆçš„å‘½ä»¤è¡Œæ¥å£
"""

import asyncio
import os
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import cli_config
from llm_dynamic.analyzer_api import DynamicLLMAnalyzerAPI
from llm_dynamic.database import get_all_products, get_products_by_keyword


async def main():
    """ä¸»ç¨‹åºå…¥å£"""
    if len(sys.argv) < 2:
        print("ğŸ¤– LLMåŠ¨æ€å•†å“åˆ†æå·¥å…·")
        print("\nä½¿ç”¨æ–¹æ³•ï¼š")
        print("  python llm_cli.py 'ä½ çš„åˆ†æéœ€æ±‚' [å…³é”®è¯] [é€‰é¡¹]")
        print("\nåŸºæœ¬é€‰é¡¹ï¼š")
        print("  --model æ¨¡å‹å       æŒ‡å®šæ¨¡å‹ï¼ˆé»˜è®¤ï¼šgpt-3.5-turboï¼‰")
        print("  --keyword å…³é”®è¯     æœç´¢å…³é”®è¯")
        print("  --limit æ•°é‡         åˆ†æå•†å“æ•°é‡ï¼ˆé»˜è®¤ï¼š10ï¼‰")
        print("  --interactive, -i    äº¤äº’æ¨¡å¼")
        print("\nä½¿ç”¨ç¤ºä¾‹ï¼š")
        print("  python llm_cli.py 'æ‰¾å‡ºæ€§ä»·æ¯”æœ€é«˜çš„iPhone'")
        print("  python llm_cli.py 'åˆ†æè¿™äº›å•†å“' iPhone --model gpt-4")
        print("  python llm_cli.py 'ç»™è´­ä¹°å»ºè®®' --keyword MacBook")
        print("  python llm_cli.py 'æŒ‰ä»·æ ¼æ’åº' --keyword iPhone --limit 15")
        print("\né…ç½®æ£€æŸ¥ï¼š")
        print("  python check_llm_env.py")
        print("\né…ç½®æŒ‡å—ï¼š")
        print("  docs/API_SETUP_GUIDE.md")
        return

    # è§£æå‘½ä»¤è¡Œå‚æ•°
    prompt = sys.argv[1]
    keyword = None
    model = None
    limit = 10

    # ç®€å•å‚æ•°è§£æ
    i = 2
    while i < len(sys.argv):
        if sys.argv[i] == "--model" and i + 1 < len(sys.argv):
            model = sys.argv[i + 1]
            i += 2
        elif sys.argv[i] == "--keyword" and i + 1 < len(sys.argv):
            keyword = sys.argv[i + 1]
            i += 2
        elif sys.argv[i] == "--limit" and i + 1 < len(sys.argv):
            limit = int(sys.argv[i + 1])
            i += 2
        elif not keyword and not sys.argv[i].startswith("--"):
            keyword = sys.argv[i]
            i += 1
        else:
            i += 1

    print(f"ğŸ¯ åˆ†æéœ€æ±‚ï¼š{prompt}")
    if keyword:
        print(f"ğŸ” å…³é”®è¯ï¼š{keyword}")
    if model:
        print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹ï¼š{model}")
    else:
        print(f"ğŸ¤– é»˜è®¤æ¨¡å‹ï¼š{cli_config.get_llm_model()}")

    print(f"ğŸ“Š åˆ†ææ•°é‡ï¼š{limit}")
    print("=" * 50)

    try:
        # éªŒè¯APIå¯†é’¥
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            print("âŒ OpenAI API å¯†é’¥æœªé…ç½®")
            print("\nğŸ’¡ é…ç½®æ–¹æ³•ï¼š")
            print("1. å¤åˆ¶ç¯å¢ƒé…ç½®ï¼šcp env.example .env")
            print("2. ç¼–è¾‘ .env æ–‡ä»¶ï¼Œè®¾ç½® OPENAI_API_KEY")
            print("3. è¯¦ç»†æŒ‡å—ï¼šdocs/API_SETUP_GUIDE.md")
            return

        # åˆå§‹åŒ–åˆ†æå™¨
        analyzer = DynamicLLMAnalyzerAPI(model=model)
        print("ğŸ”— æ­£åœ¨éªŒè¯APIè¿æ¥...")

        # æµ‹è¯•è¿æ¥
        connection_test = await analyzer.test_connection()
        if connection_test["status"] == "error":
            print(f"âŒ APIè¿æ¥å¤±è´¥ï¼š{connection_test['message']}")
            print("\nğŸ’¡ å»ºè®®è§£å†³æ–¹æ¡ˆï¼š")
            for suggestion in connection_test.get("suggestions", []):
                print(f"  â€¢ {suggestion}")
            return
        else:
            print(f"âœ… APIè¿æ¥æˆåŠŸï¼š{connection_test['message']}")

        # è·å–å•†å“æ•°æ®
        if keyword:
            products = await get_products_by_keyword(keyword, limit)
            print(f"ğŸ“¦ æ‰¾åˆ° {len(products)} ä¸ªç›¸å…³å•†å“")
        else:
            products = await get_all_products(limit)
            print(f"ğŸ“¦ è·å–æœ€æ–° {len(products)} ä¸ªå•†å“")

        if not products:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°ç›¸å…³å•†å“æ•°æ®")
            return

        print("ğŸ¤” LLMåˆ†æä¸­...")
        print("-" * 50)

        # æ‰§è¡ŒåŠ¨æ€åˆ†æ
        result = await analyzer.analyze_with_prompt(products, prompt)

        print("ğŸ‰ åˆ†æç»“æœï¼š")
        print(result)

    except Exception as e:
        error_msg = str(e)
        print(f"âŒ åˆ†æå¤±è´¥ï¼š{error_msg}")
        print("\nğŸ’¡ å¯èƒ½çš„è§£å†³æ–¹æ¡ˆï¼š")

        if "api_key" in error_msg.lower():
            print("1. æ£€æŸ¥ OPENAI_API_KEY æ˜¯å¦æ­£ç¡®é…ç½®")
            print("2. éªŒè¯APIå¯†é’¥æ ¼å¼ï¼ˆä»¥sk-å¼€å¤´ï¼‰")
        elif "rate_limit" in error_msg.lower():
            print("1. APIè¯·æ±‚é¢‘ç‡è¶…é™ï¼Œè¯·ç¨åé‡è¯•")
            print("2. è€ƒè™‘å‡çº§APIè®¡åˆ’")
        elif "model" in error_msg.lower():
            print("1. æ£€æŸ¥æ¨¡å‹åç§°æ˜¯å¦æ­£ç¡®")
            print("2. éªŒè¯è´¦æˆ·æ˜¯å¦æœ‰æ¨¡å‹è®¿é—®æƒé™")
        else:
            print("1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
            print("2. éªŒè¯APIæœåŠ¡çŠ¶æ€")
            print("3. æŸ¥çœ‹è¯¦ç»†é…ç½®æŒ‡å—ï¼šdocs/API_SETUP_GUIDE.md")

        print("4. æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶æ˜¯å¦å­˜åœ¨")
        print("5. è¿è¡Œç¯å¢ƒæ£€æŸ¥ï¼špython check_llm_env.py")


async def interactive_mode():
    """äº¤äº’æ¨¡å¼"""
    print("ğŸ¤– è¿›å…¥LLMåŠ¨æ€åˆ†æäº¤äº’æ¨¡å¼")
    print("è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡º")
    print("=" * 50)

    try:
        # éªŒè¯APIå¯†é’¥
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            print("âŒ OpenAI API å¯†é’¥æœªé…ç½®ï¼Œè¯·å…ˆé…ç½®åå†ä½¿ç”¨äº¤äº’æ¨¡å¼")
            print("\nğŸ’¡ é…ç½®æ–¹æ³•ï¼š")
            print("1. å¤åˆ¶ç¯å¢ƒé…ç½®ï¼šcp env.example .env")
            print("2. ç¼–è¾‘ .env æ–‡ä»¶ï¼Œè®¾ç½® OPENAI_API_KEY")
            print("3. è¯¦ç»†æŒ‡å—ï¼šdocs/API_SETUP_GUIDE.md")
            return

        analyzer = DynamicLLMAnalyzerAPI()

        # æµ‹è¯•è¿æ¥
        print("ğŸ”— æ­£åœ¨éªŒè¯APIè¿æ¥...")
        connection_test = await analyzer.test_connection()
        if connection_test["status"] == "error":
            print(f"âŒ APIè¿æ¥å¤±è´¥ï¼š{connection_test['message']}")
            return
        else:
            print(f"âœ… {connection_test['message']}")
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–åˆ†æå™¨å¤±è´¥ï¼š{str(e)}")
        return

    while True:
        try:
            prompt = input("\nğŸ’­ ä½ æƒ³åˆ†æä»€ä¹ˆï¼Ÿ> ").strip()

            if prompt.lower() in ["quit", "exit", "é€€å‡º"]:
                print("ğŸ‘‹ å†è§ï¼")
                break

            if not prompt:
                continue

            # ç®€å•çš„å…³é”®è¯æå–ï¼ˆç”¨æˆ·å¯ä»¥è¾“å…¥ï¼šåˆ†æiPhoneæˆ–iPhoneåˆ†æï¼‰
            keyword = None
            for word in prompt.split():
                if any(
                    brand in word.lower()
                    for brand in ["iphone", "ipad", "macbook", "apple", "è‹¹æœ"]
                ):
                    keyword = word
                    break

            # è·å–æ•°æ®
            if keyword:
                products = await get_products_by_keyword(keyword, 10)
                print(f"ğŸ“¦ æ‰¾åˆ° {len(products)} ä¸ªç›¸å…³å•†å“")
            else:
                products = await get_all_products(10)
                print(f"ğŸ“¦ è·å–æœ€æ–° {len(products)} ä¸ªå•†å“")

            if not products:
                print("âŒ æ²¡æœ‰æ‰¾åˆ°ç›¸å…³å•†å“æ•°æ®")
                continue

            print("ğŸ¤” åˆ†æä¸­...")
            result = await analyzer.analyze_with_prompt(products, prompt)
            print(f"\nğŸ‰ åˆ†æç»“æœï¼š\n{result}")

        except KeyboardInterrupt:
            print("\nğŸ‘‹ å†è§ï¼")
            break
        except Exception as e:
            error_msg = str(e)
            print(f"âŒ é”™è¯¯ï¼š{error_msg}")

            if "rate_limit" in error_msg.lower():
                print("ğŸ’¡ APIè¯·æ±‚é¢‘ç‡è¶…é™ï¼Œè¯·ç¨ç­‰ç‰‡åˆ»å†è¯•")
            elif "api_key" in error_msg.lower():
                print("ğŸ’¡ APIå¯†é’¥é—®é¢˜ï¼Œè¯·æ£€æŸ¥é…ç½®")


if __name__ == "__main__":
    # æ£€æŸ¥æ˜¯å¦æ˜¯äº¤äº’æ¨¡å¼
    if len(sys.argv) >= 2 and sys.argv[-1] in ["--interactive", "-i"]:
        asyncio.run(interactive_mode())
    else:
        asyncio.run(main())
