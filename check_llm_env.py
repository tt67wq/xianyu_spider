#!/usr/bin/env python3
"""
LLMåŠ¨æ€åˆ†ææ¨¡å—ç¯å¢ƒæ£€æŸ¥è„šæœ¬
æ£€æŸ¥Pythonç‰ˆæœ¬ã€å†…å­˜ã€Ollamaå®‰è£…çŠ¶æ€å’Œå¯ç”¨æ¨¡å‹
"""

import os
import subprocess
import sys
from typing import List, Tuple

import psutil


def check_python_version() -> Tuple[bool, str]:
    """æ£€æŸ¥Pythonç‰ˆæœ¬ï¼ˆè¦æ±‚>=3.8ï¼‰"""
    version = sys.version_info
    if version.major == 3 and version.minor >= 8:
        return (
            True,
            f"âœ… Python {version.major}.{version.minor}.{version.micro}",
        )
    else:
        return (
            False,
            f"âŒ Python {version.major}.{version.minor}.{version.micro} (éœ€è¦ >= 3.8)",
        )


def check_memory() -> Tuple[bool, str]:
    """æ£€æŸ¥ç³»ç»Ÿå†…å­˜ï¼ˆæœ€å°‘4GB/å»ºè®®8GBï¼‰"""
    try:
        memory = psutil.virtual_memory()
        total_gb = memory.total / (1024**3)

        if total_gb >= 8:
            return True, f"âœ… ç³»ç»Ÿå†…å­˜: {total_gb:.1f}GB (å……è¶³)"
        elif total_gb >= 4:
            return True, f"âš ï¸  ç³»ç»Ÿå†…å­˜: {total_gb:.1f}GB (åŸºæœ¬æ»¡è¶³ï¼Œå»ºè®®8GB)"
        else:
            return False, f"âŒ ç³»ç»Ÿå†…å­˜: {total_gb:.1f}GB (ä¸è¶³ï¼Œè‡³å°‘éœ€è¦4GB)"
    except Exception as e:
        return False, f"âŒ æ— æ³•æ£€æµ‹å†…å­˜: {str(e)}"


def check_ollama_installation() -> Tuple[bool, str]:
    """éªŒè¯Ollamaå®‰è£…"""
    try:
        result = subprocess.run(
            ["ollama", "--version"], capture_output=True, text=True, timeout=10
        )
        if result.returncode == 0:
            version = result.stdout.strip()
            return True, f"âœ… Ollamaå·²å®‰è£…: {version}"
        else:
            return False, f"âŒ Ollamaå‘½ä»¤æ‰§è¡Œå¤±è´¥: {result.stderr}"
    except subprocess.TimeoutExpired:
        return False, "âŒ Ollamaå‘½ä»¤è¶…æ—¶"
    except FileNotFoundError:
        return False, "âŒ Ollamaæœªå®‰è£…æˆ–ä¸åœ¨PATHä¸­"
    except Exception as e:
        return False, f"âŒ Ollamaæ£€æŸ¥å¤±è´¥: {str(e)}"


def check_ollama_service() -> Tuple[bool, str]:
    """æ£€æŸ¥OllamaæœåŠ¡çŠ¶æ€"""
    try:
        result = subprocess.run(
            ["ollama", "list"], capture_output=True, text=True, timeout=15
        )
        if result.returncode == 0:
            return True, "âœ… OllamaæœåŠ¡è¿è¡Œæ­£å¸¸"
        else:
            return False, f"âŒ OllamaæœåŠ¡å¼‚å¸¸: {result.stderr}"
    except subprocess.TimeoutExpired:
        return False, "âŒ OllamaæœåŠ¡å“åº”è¶…æ—¶"
    except Exception as e:
        return False, f"âŒ OllamaæœåŠ¡æ£€æŸ¥å¤±è´¥: {str(e)}"


def get_available_models() -> Tuple[bool, List[str]]:
    """è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨"""
    try:
        result = subprocess.run(
            ["ollama", "list"], capture_output=True, text=True, timeout=15
        )
        if result.returncode == 0:
            lines = result.stdout.strip().split("\n")
            models = []
            for line in lines[1:]:  # è·³è¿‡æ ‡é¢˜è¡Œ
                if line.strip():
                    model_name = line.split()[0]
                    models.append(model_name)
            return True, models
        else:
            return False, []
    except Exception:
        return False, []


def check_database_exists() -> Tuple[bool, str]:
    """æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    db_path = "database.sqlite3"
    if os.path.exists(db_path):
        size = os.path.getsize(db_path) / 1024  # KB
        return True, f"âœ… æ•°æ®åº“æ–‡ä»¶å­˜åœ¨: {size:.1f}KB"
    else:
        return False, "âŒ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨"


def check_dependencies() -> Tuple[bool, str]:
    """æ£€æŸ¥Pythonä¾èµ–"""
    required_packages = ["ollama", "tortoise", "models"]
    missing = []

    for package in required_packages:
        try:
            __import__(package)
        except ImportError:
            missing.append(package)

    if not missing:
        return True, "âœ… æ‰€æœ‰ä¾èµ–å·²å®‰è£…"
    else:
        return False, f"âŒ ç¼ºå°‘ä¾èµ–: {', '.join(missing)}"


def suggest_models() -> List[str]:
    """æ¨èçš„æ¨¡å‹åˆ—è¡¨"""
    return [
        "llama3.2 (3B, è½»é‡çº§æ¨è)",
        "qwen2.5:7b (ä¸­æ–‡ä¼˜åŒ–)",
        "mistral:7b (æ¨ç†èƒ½åŠ›å¼º)",
        "stablelm2 (å¤šç”¨é€”)",
    ]


def print_installation_guide():
    """æ‰“å°å®‰è£…æŒ‡å—"""
    print("\n" + "=" * 60)
    print("ğŸ› ï¸  å®‰è£…æŒ‡å—")
    print("=" * 60)

    print("\n1. å®‰è£…Ollama:")
    print("   curl -fsSL https://ollama.ai/install.sh | sh")

    print("\n2. å¯åŠ¨OllamaæœåŠ¡:")
    print("   ollama serve")

    print("\n3. å®‰è£…æ¨èæ¨¡å‹:")
    for model in suggest_models():
        model_name = model.split()[0]
        print(f"   ollama pull {model_name}")

    print("\n4. å®‰è£…Pythonä¾èµ–:")
    print("   uv sync")

    print("\n5. æµ‹è¯•å®‰è£…:")
    print("   python llm_cli.py 'æµ‹è¯•åŠŸèƒ½'")


def main():
    """ä¸»æ£€æŸ¥ç¨‹åº"""
    print("ğŸ” LLMåŠ¨æ€åˆ†ææ¨¡å—ç¯å¢ƒæ£€æŸ¥")
    print("=" * 60)

    checks = [
        ("Pythonç‰ˆæœ¬", check_python_version),
        ("ç³»ç»Ÿå†…å­˜", check_memory),
        ("Ollamaå®‰è£…", check_ollama_installation),
        ("OllamaæœåŠ¡", check_ollama_service),
        ("æ•°æ®åº“æ–‡ä»¶", check_database_exists),
        ("Pythonä¾èµ–", check_dependencies),
    ]

    all_passed = True

    for name, check_func in checks:
        success, message = check_func()
        print(f"{name:12} | {message}")
        if not success:
            all_passed = False

    print("\n" + "-" * 60)

    # æ£€æŸ¥å¯ç”¨æ¨¡å‹
    print("ğŸ“‹ å¯ç”¨æ¨¡å‹:")
    success, models = get_available_models()
    if success and models:
        for model in models:
            print(f"   âœ… {model}")
    else:
        print("   âŒ æ²¡æœ‰å¯ç”¨æ¨¡å‹")
        all_passed = False

    print("\n" + "-" * 60)

    if all_passed:
        print("ğŸ‰ ç¯å¢ƒæ£€æŸ¥é€šè¿‡ï¼å¯ä»¥å¼€å§‹ä½¿ç”¨LLMåŠ¨æ€åˆ†æåŠŸèƒ½")
        print("\nå¿«é€Ÿå¼€å§‹:")
        print("   python llm_cli.py 'æ‰¾å‡ºæ€§ä»·æ¯”æœ€é«˜çš„å•†å“'")
        print("   python llm_cli.py 'åˆ†æiPhoneä»·æ ¼è¶‹åŠ¿' iPhone")
        print("   python llm_cli.py --interactive  # äº¤äº’æ¨¡å¼")
    else:
        print("âŒ ç¯å¢ƒæ£€æŸ¥æœªé€šè¿‡ï¼Œè¯·å‚è€ƒå®‰è£…æŒ‡å—")
        print_installation_guide()

    print("\n" + "=" * 60)
    print("ğŸ’¡ æ¨èæ¨¡å‹:")
    for model in suggest_models():
        print(f"   â€¢ {model}")


if __name__ == "__main__":
    main()
